---
title: "Random Forest Scripts"
author: "Bill Lang"
date: "7/7/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(randomForest)
```


Loading in all the data that was created in ```Cleaning and Geocoding```. 

```{r}
load("trainingData.RData")
load("geocodeFileNoHse.RData")
load("missingArea.RData")
load("boston.RData")
```

Model Building on the first 15,000

This model is built on a random shuffle of the data and validated by holding out 20% of the dataset. A large confusion matrix is generated alongside the actual different statistics. 
 
```{r}
modelData <- firstGeocodeFile 
set.seed(343)

shuf <- sample(nrow(modelData))
modelData <- modelData[shuf,]
train <- sample(nrow(modelData)*.8)
bostonTrain <- modelData[train,]
bostonTest <- modelData[-train,]

length(unique(modelData$Area))
length(unique(bostonTrain$Area))
length(unique(bostonTest$Area))
```


```{r}
bag <- randomForest(Area ~ latitude + longitude + Year + Total.rooms + Price.type, data = bostonTrain, ntree = 1000, mtry = 2, importance = TRUE)
yhat.rf <- predict(bag, newdata = bostonTest)
misclassRate <- mean(yhat.rf != bostonTest$Area)
misclassRate

predicted <- cbind(yhat.rf, bostonTest)
predicted
```

We can then map the results using the ggmaps package below to manuely search for any errors.

```{r}
k <- "AIzaSyDNMoGGfgl9f5KtGCnp9BegNb7ZDqPu7gg"
register_google(key = k)
```

```{r}
map <- get_map(location = 'Boston', zoom = 9, maptype = "terrain-background", source = 'google', color = 'color')
ggmap(map) + geom_point(data = modelData, mapping = aes(x = longitude, y = latitude, color = factor(Area)), size = 1)
```


Full Model

Using all the available data we construct a full model to use for the rest of the analysis. 

```{r}
fullModel <- randomForest(Area ~ latitude + longitude + Year + Total.rooms + Price.type, data = firstGeocodeFile, ntree = 1000, mtry = 2, importance = TRUE)
```
















Predict the data from the previous model and get another misclassification rate. 

```{r}
yhat.rf <- predict(fullModel, newdata = geocodeFileNoHse)
predicted <- cbind(yhat.rf, geocodeFileNoHse)
predicted

misclassNoHse <- mean(yhat.rf != geocodeFileNoHse$Area)
misclassNoHse
```

Mapping the predicted results. 

```{r}
map <- get_map(location = 'Boston', zoom = 10, maptype = "terrain-background", source = 'google', color = 'color')
ggmap(map) + geom_point(data = predicted, mapping = aes(x = longitude, y = latitude, color = factor(yhat.rf)), size = 1)
```











Predict the data using the previous model and map the results for validation. 

```{r}
yhat.rf <- predict(fullModel, newdata = geocodeFileClassify)
predicted <- cbind(yhat.rf, geocodeFileClassify)
predicted
```


```{r}
map <- get_map(location = 'Boston', zoom = 8, maptype = "terrain-background", source = 'google', color = 'color')
ggmap(map) + geom_point(data = predicted, mapping = aes(x = longitude, y = latitude, color = factor(yhat.rf)), size = 1)
```






