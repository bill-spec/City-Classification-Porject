---
title: "Boston Classification"
author: "Bill Lang"
date: "7/1/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidygeocoder)
library(randomForest)
library(ggmap)
```


This first half will construct a random forest model on the 15,713 observations that have a full address and an area specification in the top 50.

Reading in file.

```{r}
boston <- read.csv("C:/Users/Billy/Desktop/hipHop/hiphop_boston.csv")
boston
saveRDS(boston, file = "boston.RData")
boston <- readRDS("boston.RData")
boston
```

Removing areas with no information. 

```{r}
boston <- boston %>% filter(Area != "") 
```

Finding the top 50 labeled areas.

```{r}
boston$Area <- tolower(boston$Area)
tbl <- boston %>% group_by(Area) %>% summarise(count = n()) %>% arrange(desc(count))
listOfAreas <- tbl[1:50,]$Area
listOfAreas
```

Finding the observations with a top 50 observation. 

```{r}
boston <- boston %>% filter(Area %in% listOfAreas) 
bostonAddress <- boston %>% unite(Address, c("Hse.No","Street","Area"), sep = " ",remove = FALSE)
bostonAddress$Address <- paste(bostonAddress$Address, " , MA")
bostonAddress
```

Finding the 15,713 observations with full addresses.

```{r}
bostonAddress <- bostonAddress %>% filter((Street != "") | (Cross.Street != "")) %>% filter(Hse.No != "")
bostonAddress
```

Geocoding those addresses and saving them to a file on my desktop (to circumvent geocoding again)
 
```{r}
geocodeFileFull <- tidygeocoder::geocode(.tbl = bostonAddress, address = Address, method = "osm", lat = latitude, long = longitude)
geocodeFile <- geocodeFileFull
#write.csv(geocodeFile, file = "C:/Users/Billy/Desktop/Storage/OSMgeocodedCSV.csv", row.names = FALSE)
#geocodeFile <- read.csv("C:/Users/Billy/Desktop/Storage/OSMgeocodedCSV.csv")
save(geocodeFile, file = "first.RData")
```

Filtering outliers in the geocoding process. These results were so far outside of Boston they are being treated as failed geocoding results.

```{r}
geocodeFile
geocodeFile <- geocodeFile %>% filter(!is.na(latitude))
geocodeFile$Area <- as.factor(geocodeFile$Area)
geocodeFile <- geocodeFile %>% filter(latitude < 43) %>% filter(latitude > 42) %>% filter(longitude > -71.75)
geocodeFile
```

Preparing the dataset for a model. Shfiting all character variables to lowercase and set to factors. The average total number of rooms is 5 and is used to replace any NAs in that column.  

```{r}
bostonArea <- geocodeFile

bostonArea$Price.type <- tolower(bostonArea$Price.type)
bostonArea$Price.type <- as.factor(bostonArea$Price.type)

bostonArea$Type <- tolower(bostonArea$Type)

bostonArea$Column <- tolower(bostonArea$Column)
bostonArea$Type <- as.factor(bostonArea$Type)
bostonArea$Total.rooms <- as.integer(bostonArea$Total.rooms)

geocodeFile <- bostonArea

#5 is the mean of totalrooms
geocodeFile <- geocodeFile %>% mutate(Total.rooms = replace_na(Total.rooms,5))
geocodeFile
str(geocodeFile)
```

Model Building

This model is built on a random shuffle of the data and validated by holding out 20% of the dataset. A large confusion matrix is generated alongside the actual different statistics. 
 
```{r}
bostonArea <- geocodeFile 
set.seed(343)

shuf <- sample(nrow(bostonArea))
bostonArea <- bostonArea[shuf,]
train <- sample(nrow(bostonArea)*.8)
bostonTrain <- bostonArea[train,]
bostonTest <- bostonArea[-train,]

length(unique(bostonArea$Area))
length(unique(bostonTrain$Area))
length(unique(bostonTest$Area))
```


```{r}
bag <- randomForest(Area ~ latitude + longitude + Year + Total.rooms + Price.type, data = bostonTrain, ntree = 1000, mtry = 2, importance = TRUE)
yhat.rf <- predict(bag, newdata = bostonTest)
misclassRate <- mean(yhat.rf != bostonTest$Area)
misclassRate
predicted <- cbind(yhat.rf, bostonTest)
predicted
```

Confusion Matrix

```{r}

```



Cross Validation 

To get a better estimate of the test error rate the model is cross validated below. 

```{r}
shuf <- sample(nrow(bostonArea))
bostonArea <- bostonArea[shuf,]
ind1 <- c(1, 1311, 2621, 3931, 5241, 6551, 7861, 9171, 10481, 11791)
ind2 <- c(1310, 2620, 3930, 5240, 6550, 7860, 9170, 10480, 11790, 13100)
rates <- c(1:10)
for(i in 1:10){
	tempTrain <- bostonArea[-(ind1[i]:ind2[i]),]
	tempTest <- bostonArea[ind1[i]:ind2[i],]

  bag <- randomForest(Area ~ latitude + longitude + Year + Total.rooms, data = tempTrain, ntree = 1000, mtry = 2, importance = TRUE)
  yhat.rf <- predict(bag, newdata = tempTest)
  rates[i] <- mean(yhat.rf != tempTest$Area)
}
mean(rates)
rates
```

We can then map the results using the ggmaps package below to manuely search for any errors.

```{r}
k <- "AIzaSyDNMoGGfgl9f5KtGCnp9BegNb7ZDqPu7gg"
register_google(key = k)
```


```{r}
map <- get_map(location = 'Boston', zoom = 10, maptype = "terrain-background", source = 'google', color = 'color')
ggmap(map) + geom_point(data = predicted, mapping = aes(x = longitude, y = latitude, color = factor(yhat.rf)), size = 1)
```


Full Model
Using all the available data we can construct a full model to use for the rest of the analysis.

```{r}
fullModel <- randomForest(Area ~ latitude + longitude + Year + Total.rooms + Price.type, data = geocodeFile, ntree = 1000, mtry = 2, importance = TRUE)
```



The next goal is to investigate how well this model works on the 8871 observations that don't have a house number. This will depend on the quality of the geocoding and how well the model does. 


First we can re-clean the data from earlier to get the 8,871.

```{r}
boston <- read.csv("C:/Users/Billy/Desktop/hipHop/hiphop_boston.csv")
boston
```

```{r}
boston <- boston %>% filter(Area != "")
```

```{r}
boston$Area <- tolower(boston$Area)
boston <- boston %>% filter(Area %in% listOfAreas)
bostonAddress <- boston %>% unite(Address, c("Hse.No","Street","Area"), sep = " ",remove = FALSE)
bostonAddress$Address <- paste(bostonAddress$Address, " , MA")
bostonAddress
```

```{r}
boston <- boston %>% filter(Area != "") %>% filter((Street != "") | (Cross.Street != "")) %>% filter(Hse.No == "")
boston
```

Geocoding and saving the files same as before. 
 
```{r}
geocodeFileFull <- tidygeocoder::geocode(.tbl = bostonAddress, address = Address, method = "osm", lat = latitude, long = longitude)
geocodeFileNoHse <- geocodeFileFull
write.csv(geocodeFileNoHse, file = "C:/Users/Billy/Desktop/Storage/OSMgeocodedNoHSECSV.csv", row.names = FALSE)
geocodeFileNoHse <- read.csv("C:/Users/Billy/Desktop/Storage/OSMgeocodedNoHSECSV.csv") 
```

```{r}
geocodeFileNoHse <- geocodeFileNoHse %>% filter(!is.na(latitude))
geocodeFileNoHse$Area <- as.factor(geocodeFileNoHse$Area)
geocodeFileNoHse <- geocodeFileNoHse %>% filter(latitude < 43) %>% filter(latitude > 42) %>% filter(longitude > -71.75)
geocodeFileNoHse
```

```{r}
geocodeFileNoHse <- geocodeFileNoHse %>% filter(Area %in% listOfAreas)
bostonArea <- geocodeFileNoHse

bostonArea$Price.type <- tolower(bostonArea$Price.type)
bostonArea$Price.type <- as.factor(bostonArea$Price.type)

bostonArea$Type <- tolower(bostonArea$Type)

bostonArea$Column <- tolower(bostonArea$Column)
bostonArea$Type <- as.factor(bostonArea$Type)
bostonArea$Total.rooms <- as.integer(bostonArea$Total.rooms)

geocodeFileNoHse <- bostonArea

#5 is the mean of totalrooms
geocodeFileNoHse <- geocodeFileNoHse %>% mutate(Total.rooms = replace_na(Total.rooms,5))
geocodeFileNoHse
str(geocodeFileNoHse)
```

Predict the data from the previous model and get a misclass rate. 

```{r}

yhat.rf <- predict(fullModel, newdata = geocodeFileNoHse)
predicted <- cbind(yhat.rf, geocodeFileNoHse)
predicted

setdiff(a,b)
a;b
a <- unique(geocodeFile$Area)
b <- unique(geocodeFileNoHse$Area) 

misclassNoHse <- mean(yhat.rf != geocodeFileNoHse$Area)
misclassNoHse
```



```{r}
map <- get_map(location = 'Boston', zoom = 10, maptype = "terrain-background", source = 'google', color = 'color')
ggmap(map) + geom_point(data = predicted, mapping = aes(x = longitude, y = latitude, color = factor(yhat.rf)), size = 1)
```


```{r}

```


Next we can take the 37,506 observations that aren't inside the top 50 regions, and predict the most likely region to classify them in.

```{r}
boston <- read.csv("C:/Users/Billy/Desktop/hipHop/hiphop_boston.csv")
boston
```

```{r}
boston$Area <- tolower(boston$Area)
boston <- boston %>% filter(!(Area %in% listOfAreas))
bostonAddress <- boston %>% unite(Address, c("Hse.No","Street","Area"), sep = " ",remove = FALSE)
bostonAddress$Address <- paste(bostonAddress$Address, " , MA")
bostonAddress
```

Geocoding and saving the files same as before. 
 
```{r}
geocodeFileFull <- tidygeocoder::geocode(.tbl = bostonAddress, address = Address, method = "osm", lat = latitude, long = longitude)
geocodeFileNoHse <- geocodeFileFull
write.csv(geocodeFileNoHse, file = "C:/Users/Billy/Desktop/Storage/OSMgeocodedNoAREA.csv", row.names = FALSE)
geocodeFileNoHse <- read.csv("C:/Users/Billy/Desktop/Storage/OSMgeocodedNoAREA.csv") 
```

```{r}
geocodeFileNoHse <- geocodeFileNoHse %>% filter(!is.na(latitude))
geocodeFileNoHse$Area <- as.factor(geocodeFileNoHse$Area)
geocodeFileNoHse <- geocodeFileNoHse %>% filter(latitude < 43) %>% filter(latitude > 42) %>% filter(longitude > -71.75)
geocodeFileNoHse
```

```{r}
geocodeFileNoHse <- geocodeFileNoHse %>% filter(Area %in% listOfAreas)
bostonArea <- geocodeFileNoHse

bostonArea$Price.type <- tolower(bostonArea$Price.type)
bostonArea$Price.type <- as.factor(bostonArea$Price.type)

bostonArea$Type <- tolower(bostonArea$Type)

bostonArea$Column <- tolower(bostonArea$Column)
bostonArea$Type <- as.factor(bostonArea$Type)
bostonArea$Total.rooms <- as.integer(bostonArea$Total.rooms)

geocodeFileNoHse <- bostonArea

#5 is the mean of totalrooms
geocodeFileNoHse <- geocodeFileNoHse %>% mutate(Total.rooms = replace_na(Total.rooms,5))
geocodeFileNoHse
str(geocodeFileNoHse)
```

Predict the data from the previous model and map the results for validation.

```{r}

yhat.rf <- predict(fullModel, newdata = geocodeFileNoHse)
predicted <- cbind(yhat.rf, geocodeFileNoHse)
predicted

setdiff(a,b)
a;b
a <- unique(geocodeFile$Area)
b <- unique(geocodeFileNoHse$Area) 

misclassNoHse <- mean(yhat.rf != geocodeFileNoHse$Area)
misclassNoHse
```


```{r}
map <- get_map(location = 'Boston', zoom = 10, maptype = "terrain-background", source = 'google', color = 'color')
ggmap(map) + geom_point(data = predicted, mapping = aes(x = longitude, y = latitude, color = factor(yhat.rf)), size = 1)
```


```{r}

```


