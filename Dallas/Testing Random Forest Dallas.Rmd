---
title: "Testing Random Forest Dallas"
author: "Bill Lang"
date: "10/14/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidygeocoder)
library(ggmap)
```


Next we can take the 37,506 observations that aren't inside the top 50 regions, predict the most likely region to classify them in, and investigate if the results seem correct.

```{r}
load(file = "cleanDallas.RData")
dallasData
```

```{r}
dallasDataAddress <- dallasData %>% filter(!(Area %in% listOfAreas))
dallasDataAddress 
```

```{r}
dallasDataAddress <- dallasDataAddress %>% filter(!is.na(latitude))
dallasDataAddress
```

Predict the data using the previous model and map the results for validation. 

```{r}
yhat.rf <- predict(fullModel, newdata = dallasDataAddress)
predicted <- cbind(dallasDataAddress,yhat.rf)
predicted <- predicted %>% mutate(calculatedColumn = yhat.rf) %>% select(-yhat.rf)
predicted

#Saving for the predicted file
save(predicted, file = "predicctedBoston.RData")
```


```{r}
map <- get_map(location = 'Dallas', zoom = 10 , maptype = "terrain-background", source = 'google', color = 'color')
ggmap(map) + geom_point(data = predicted, mapping = aes(x = longitude, y = latitude, color = factor(yhat.rf)), size = .1)+ theme(legend.position = "none")
```







